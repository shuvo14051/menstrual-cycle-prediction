{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11de294-ba9b-4a3d-b54f-87b250461556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", message=\"subprocess.run\")\n",
    "\n",
    "%run utility_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3fea60-6a19-40a7-ba91-a821f64cc064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547, 25)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"data/Original_Preprocessed_data.csv\")\n",
    "df_original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c52f2-a9ef-4c40-843b-0737a59ca145",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76842a85-6502-4e3f-be51-2f96f96a3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_original.drop('Healthy', axis=1)\n",
    "y = df_original['Healthy']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e67cf9de-c6c5-402e-b475-0584c4d0479b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1237, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586993b9-2168-4a6c-9934-2b631d54ff73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Healthy\n",
       "1    1183\n",
       "0      54\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a7a3d-0b01-47ad-b2bc-b0241df8c5ec",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f9d456-31d5-44ef-b47c-b394a60b6217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\younu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\younu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 546, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\younu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1022, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\younu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1491, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Upsample the minority class\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4b390d-1bf7-42e3-bbe1-40cdf8dfa00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.to_csv(\"X_test.csv\", index=None)\n",
    "# y_test.to_csv(\"y_test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf58b57-7c1d-48f5-992e-e3740d12f4af",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e72fe97-a3a9-48fb-afaa-a09f9243031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde80c8-fcad-4faf-bf5a-f4b3b77f6998",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db09ce7e-1320-4369-bac2-eedca22ea9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Test result ===========================\n",
      "Accuracy: 0.9451612903225807\n",
      "AUC Score: 0.9346024346024346\n",
      "F1 Score: 0.9706390328151986\n",
      "Specificity: 0.9230769230769231\n",
      "Sensitivity: 0.9461279461279462\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.92      0.59        13\n",
      "           1       1.00      0.95      0.97       297\n",
      "\n",
      "    accuracy                           0.95       310\n",
      "   macro avg       0.71      0.93      0.78       310\n",
      "weighted avg       0.97      0.95      0.95       310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "rf_classifier = LogisticRegression(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "print(\"============================= Test result ===========================\")\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "evaluate_classifier(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b7972-fe98-4a9b-989e-fafcb35337bb",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0768cd1b-e334-4d54-8101-c4a535703005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Test result ===========================\n",
      "Accuracy: 0.9967741935483871\n",
      "AUC Score: 0.9615384615384616\n",
      "F1 Score: 0.9983193277310924\n",
      "Specificity: 0.9230769230769231\n",
      "Sensitivity: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       1.00      1.00      1.00       297\n",
      "\n",
      "    accuracy                           1.00       310\n",
      "   macro avg       1.00      0.96      0.98       310\n",
      "weighted avg       1.00      1.00      1.00       310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_random = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "clf_random.fit(X_train, y_train)\n",
    "\n",
    "print(\"============================= Test result ===========================\")\n",
    "y_pred = clf_random.predict(X_test)\n",
    "evaluate_classifier(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd7b13d2-821c-4362-99ea-e7f51ad66b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.82238 | val_0_auc: 0.69412 |  0:00:00s\n",
      "epoch 1  | loss: 0.46992 | val_0_auc: 0.75136 |  0:00:00s\n",
      "epoch 2  | loss: 0.30317 | val_0_auc: 0.87231 |  0:00:00s\n",
      "epoch 3  | loss: 0.22504 | val_0_auc: 0.84745 |  0:00:00s\n",
      "epoch 4  | loss: 0.17766 | val_0_auc: 0.90339 |  0:00:01s\n",
      "epoch 5  | loss: 0.13745 | val_0_auc: 0.90417 |  0:00:01s\n",
      "epoch 6  | loss: 0.12633 | val_0_auc: 0.94457 |  0:00:01s\n",
      "epoch 7  | loss: 0.10482 | val_0_auc: 0.91608 |  0:00:01s\n",
      "epoch 8  | loss: 0.09595 | val_0_auc: 0.91997 |  0:00:02s\n",
      "epoch 9  | loss: 0.09239 | val_0_auc: 0.92023 |  0:00:02s\n",
      "epoch 10 | loss: 0.08058 | val_0_auc: 0.91453 |  0:00:02s\n",
      "epoch 11 | loss: 0.08124 | val_0_auc: 0.90106 |  0:00:03s\n",
      "epoch 12 | loss: 0.07816 | val_0_auc: 0.91142 |  0:00:03s\n",
      "epoch 13 | loss: 0.06422 | val_0_auc: 0.85341 |  0:00:03s\n",
      "epoch 14 | loss: 0.07015 | val_0_auc: 0.856   |  0:00:03s\n",
      "epoch 15 | loss: 0.06633 | val_0_auc: 0.86506 |  0:00:04s\n",
      "epoch 16 | loss: 0.06488 | val_0_auc: 0.98601 |  0:00:04s\n",
      "epoch 17 | loss: 0.062   | val_0_auc: 0.99767 |  0:00:04s\n",
      "epoch 18 | loss: 0.0636  | val_0_auc: 0.9956  |  0:00:04s\n",
      "epoch 19 | loss: 0.06292 | val_0_auc: 0.99534 |  0:00:05s\n",
      "epoch 20 | loss: 0.04993 | val_0_auc: 0.99482 |  0:00:05s\n",
      "epoch 21 | loss: 0.04701 | val_0_auc: 0.99637 |  0:00:05s\n",
      "epoch 22 | loss: 0.0298  | val_0_auc: 0.99689 |  0:00:06s\n",
      "epoch 23 | loss: 0.04342 | val_0_auc: 0.99689 |  0:00:06s\n",
      "epoch 24 | loss: 0.03401 | val_0_auc: 0.99482 |  0:00:06s\n",
      "epoch 25 | loss: 0.02733 | val_0_auc: 0.96737 |  0:00:07s\n",
      "epoch 26 | loss: 0.02755 | val_0_auc: 0.94328 |  0:00:07s\n",
      "epoch 27 | loss: 0.02094 | val_0_auc: 0.93939 |  0:00:07s\n",
      "epoch 28 | loss: 0.02009 | val_0_auc: 0.94431 |  0:00:08s\n",
      "epoch 29 | loss: 0.01433 | val_0_auc: 0.9741  |  0:00:08s\n",
      "epoch 30 | loss: 0.01573 | val_0_auc: 0.96426 |  0:00:08s\n",
      "epoch 31 | loss: 0.02278 | val_0_auc: 0.95571 |  0:00:09s\n",
      "epoch 32 | loss: 0.03549 | val_0_auc: 0.9526  |  0:00:09s\n",
      "epoch 33 | loss: 0.02091 | val_0_auc: 0.96607 |  0:00:10s\n",
      "epoch 34 | loss: 0.02255 | val_0_auc: 0.98032 |  0:00:10s\n",
      "epoch 35 | loss: 0.0198  | val_0_auc: 0.99119 |  0:00:10s\n",
      "epoch 36 | loss: 0.03625 | val_0_auc: 0.99637 |  0:00:11s\n",
      "epoch 37 | loss: 0.0193  | val_0_auc: 0.99845 |  0:00:11s\n",
      "epoch 38 | loss: 0.0151  | val_0_auc: 0.9987  |  0:00:11s\n",
      "epoch 39 | loss: 0.01359 | val_0_auc: 0.99715 |  0:00:12s\n",
      "epoch 40 | loss: 0.0151  | val_0_auc: 0.99637 |  0:00:12s\n",
      "epoch 41 | loss: 0.01054 | val_0_auc: 0.99663 |  0:00:12s\n",
      "epoch 42 | loss: 0.02406 | val_0_auc: 0.99145 |  0:00:13s\n",
      "epoch 43 | loss: 0.01005 | val_0_auc: 0.98964 |  0:00:13s\n",
      "epoch 44 | loss: 0.01506 | val_0_auc: 0.9697  |  0:00:14s\n",
      "epoch 45 | loss: 0.01015 | val_0_auc: 0.94095 |  0:00:14s\n",
      "epoch 46 | loss: 0.02448 | val_0_auc: 0.95934 |  0:00:15s\n",
      "epoch 47 | loss: 0.00963 | val_0_auc: 0.98472 |  0:00:15s\n",
      "epoch 48 | loss: 0.00961 | val_0_auc: 0.98213 |  0:00:16s\n",
      "epoch 49 | loss: 0.01324 | val_0_auc: 0.97151 |  0:00:16s\n",
      "epoch 50 | loss: 0.01898 | val_0_auc: 0.96866 |  0:00:16s\n",
      "epoch 51 | loss: 0.01672 | val_0_auc: 0.97384 |  0:00:17s\n",
      "epoch 52 | loss: 0.00806 | val_0_auc: 0.97591 |  0:00:17s\n",
      "epoch 53 | loss: 0.01611 | val_0_auc: 0.97255 |  0:00:17s\n",
      "epoch 54 | loss: 0.00806 | val_0_auc: 0.95636 |  0:00:18s\n",
      "epoch 55 | loss: 0.00979 | val_0_auc: 0.9447  |  0:00:18s\n",
      "epoch 56 | loss: 0.01474 | val_0_auc: 0.93279 |  0:00:19s\n",
      "epoch 57 | loss: 0.01522 | val_0_auc: 0.92748 |  0:00:19s\n",
      "epoch 58 | loss: 0.0153  | val_0_auc: 0.92515 |  0:00:19s\n",
      "epoch 59 | loss: 0.0167  | val_0_auc: 0.92502 |  0:00:20s\n",
      "epoch 60 | loss: 0.01852 | val_0_auc: 0.92877 |  0:00:20s\n",
      "epoch 61 | loss: 0.01466 | val_0_auc: 0.93136 |  0:00:21s\n",
      "epoch 62 | loss: 0.01309 | val_0_auc: 0.93434 |  0:00:21s\n",
      "epoch 63 | loss: 0.02019 | val_0_auc: 0.93395 |  0:00:21s\n",
      "epoch 64 | loss: 0.01448 | val_0_auc: 0.93149 |  0:00:22s\n",
      "epoch 65 | loss: 0.01363 | val_0_auc: 0.93059 |  0:00:22s\n",
      "epoch 66 | loss: 0.01633 | val_0_auc: 0.93059 |  0:00:23s\n",
      "epoch 67 | loss: 0.01237 | val_0_auc: 0.93136 |  0:00:23s\n",
      "epoch 68 | loss: 0.0102  | val_0_auc: 0.93162 |  0:00:23s\n",
      "epoch 69 | loss: 0.01143 | val_0_auc: 0.92476 |  0:00:24s\n",
      "epoch 70 | loss: 0.01433 | val_0_auc: 0.92903 |  0:00:24s\n",
      "epoch 71 | loss: 0.00441 | val_0_auc: 0.92813 |  0:00:25s\n",
      "epoch 72 | loss: 0.00811 | val_0_auc: 0.92761 |  0:00:25s\n",
      "epoch 73 | loss: 0.0069  | val_0_auc: 0.92865 |  0:00:25s\n",
      "epoch 74 | loss: 0.00325 | val_0_auc: 0.93046 |  0:00:26s\n",
      "epoch 75 | loss: 0.00744 | val_0_auc: 0.92554 |  0:00:26s\n",
      "epoch 76 | loss: 0.01895 | val_0_auc: 0.92489 |  0:00:27s\n",
      "epoch 77 | loss: 0.00487 | val_0_auc: 0.92476 |  0:00:27s\n",
      "epoch 78 | loss: 0.00513 | val_0_auc: 0.92567 |  0:00:28s\n",
      "epoch 79 | loss: 0.00306 | val_0_auc: 0.9258  |  0:00:28s\n",
      "epoch 80 | loss: 0.00392 | val_0_auc: 0.92618 |  0:00:28s\n",
      "epoch 81 | loss: 0.0034  | val_0_auc: 0.92606 |  0:00:29s\n",
      "epoch 82 | loss: 0.00656 | val_0_auc: 0.92631 |  0:00:29s\n",
      "epoch 83 | loss: 0.00451 | val_0_auc: 0.92657 |  0:00:30s\n",
      "epoch 84 | loss: 0.00511 | val_0_auc: 0.9368  |  0:00:30s\n",
      "epoch 85 | loss: 0.00709 | val_0_auc: 0.93667 |  0:00:31s\n",
      "epoch 86 | loss: 0.00835 | val_0_auc: 0.93719 |  0:00:31s\n",
      "epoch 87 | loss: 0.00489 | val_0_auc: 0.93823 |  0:00:31s\n",
      "epoch 88 | loss: 0.00322 | val_0_auc: 0.93706 |  0:00:32s\n",
      "epoch 89 | loss: 0.00322 | val_0_auc: 0.93629 |  0:00:32s\n",
      "epoch 90 | loss: 0.00876 | val_0_auc: 0.92852 |  0:00:33s\n",
      "epoch 91 | loss: 0.00326 | val_0_auc: 0.95947 |  0:00:33s\n",
      "epoch 92 | loss: 0.00642 | val_0_auc: 0.94949 |  0:00:34s\n",
      "epoch 93 | loss: 0.01384 | val_0_auc: 0.95973 |  0:00:34s\n",
      "epoch 94 | loss: 0.01053 | val_0_auc: 0.9741  |  0:00:35s\n",
      "epoch 95 | loss: 0.01271 | val_0_auc: 0.98964 |  0:00:35s\n",
      "epoch 96 | loss: 0.0108  | val_0_auc: 0.92813 |  0:00:35s\n",
      "epoch 97 | loss: 0.03011 | val_0_auc: 0.90637 |  0:00:36s\n",
      "epoch 98 | loss: 0.01108 | val_0_auc: 0.89718 |  0:00:36s\n",
      "epoch 99 | loss: 0.01259 | val_0_auc: 0.90391 |  0:00:37s\n",
      "epoch 100| loss: 0.00835 | val_0_auc: 0.98174 |  0:00:37s\n",
      "epoch 101| loss: 0.00525 | val_0_auc: 0.92852 |  0:00:38s\n",
      "epoch 102| loss: 0.00875 | val_0_auc: 0.928   |  0:00:38s\n",
      "epoch 103| loss: 0.00894 | val_0_auc: 0.92683 |  0:00:39s\n",
      "epoch 104| loss: 0.00584 | val_0_auc: 0.9258  |  0:00:39s\n",
      "epoch 105| loss: 0.01892 | val_0_auc: 0.92554 |  0:00:40s\n",
      "epoch 106| loss: 0.00601 | val_0_auc: 0.92528 |  0:00:40s\n",
      "epoch 107| loss: 0.00458 | val_0_auc: 0.92463 |  0:00:41s\n",
      "epoch 108| loss: 0.00593 | val_0_auc: 0.92489 |  0:00:41s\n",
      "epoch 109| loss: 0.0069  | val_0_auc: 0.92502 |  0:00:41s\n",
      "epoch 110| loss: 0.00864 | val_0_auc: 0.92515 |  0:00:42s\n",
      "epoch 111| loss: 0.01621 | val_0_auc: 0.98368 |  0:00:42s\n",
      "epoch 112| loss: 0.03127 | val_0_auc: 0.96594 |  0:00:43s\n",
      "epoch 113| loss: 0.04399 | val_0_auc: 0.96167 |  0:00:43s\n",
      "epoch 114| loss: 0.02898 | val_0_auc: 0.98679 |  0:00:44s\n",
      "epoch 115| loss: 0.01806 | val_0_auc: 0.98912 |  0:00:44s\n",
      "epoch 116| loss: 0.03208 | val_0_auc: 0.98187 |  0:00:44s\n",
      "epoch 117| loss: 0.07616 | val_0_auc: 0.92295 |  0:00:45s\n",
      "epoch 118| loss: 0.06708 | val_0_auc: 0.9956  |  0:00:45s\n",
      "epoch 119| loss: 0.04196 | val_0_auc: 0.99352 |  0:00:46s\n",
      "epoch 120| loss: 0.08121 | val_0_auc: 0.95364 |  0:00:46s\n",
      "epoch 121| loss: 0.05594 | val_0_auc: 0.99145 |  0:00:47s\n",
      "epoch 122| loss: 0.03691 | val_0_auc: 0.98886 |  0:00:47s\n",
      "epoch 123| loss: 0.03386 | val_0_auc: 0.97643 |  0:00:48s\n",
      "epoch 124| loss: 0.04097 | val_0_auc: 0.9596  |  0:00:48s\n",
      "epoch 125| loss: 0.02369 | val_0_auc: 0.97436 |  0:00:49s\n",
      "epoch 126| loss: 0.0363  | val_0_auc: 0.97539 |  0:00:49s\n",
      "epoch 127| loss: 0.0536  | val_0_auc: 0.97617 |  0:00:50s\n",
      "epoch 128| loss: 0.04951 | val_0_auc: 0.97824 |  0:00:50s\n",
      "epoch 129| loss: 0.04453 | val_0_auc: 0.99663 |  0:00:51s\n",
      "epoch 130| loss: 0.02766 | val_0_auc: 0.99845 |  0:00:51s\n",
      "epoch 131| loss: 0.02317 | val_0_auc: 0.99611 |  0:00:51s\n",
      "epoch 132| loss: 0.01604 | val_0_auc: 0.97591 |  0:00:52s\n",
      "epoch 133| loss: 0.02378 | val_0_auc: 0.96814 |  0:00:52s\n",
      "epoch 134| loss: 0.02692 | val_0_auc: 0.99922 |  0:00:53s\n",
      "epoch 135| loss: 0.02628 | val_0_auc: 0.9987  |  0:00:53s\n",
      "epoch 136| loss: 0.02506 | val_0_auc: 0.9987  |  0:00:54s\n",
      "epoch 137| loss: 0.01811 | val_0_auc: 0.92877 |  0:00:54s\n",
      "epoch 138| loss: 0.01881 | val_0_auc: 0.9245  |  0:00:55s\n",
      "epoch 139| loss: 0.01649 | val_0_auc: 0.92372 |  0:00:55s\n",
      "epoch 140| loss: 0.01215 | val_0_auc: 0.92308 |  0:00:55s\n",
      "epoch 141| loss: 0.0128  | val_0_auc: 0.92359 |  0:00:56s\n",
      "epoch 142| loss: 0.0196  | val_0_auc: 0.92321 |  0:00:56s\n",
      "epoch 143| loss: 0.01105 | val_0_auc: 0.92308 |  0:00:57s\n",
      "epoch 144| loss: 0.01165 | val_0_auc: 0.92308 |  0:00:57s\n",
      "epoch 145| loss: 0.01275 | val_0_auc: 0.92139 |  0:00:58s\n",
      "epoch 146| loss: 0.01261 | val_0_auc: 0.86661 |  0:00:58s\n",
      "epoch 147| loss: 0.01169 | val_0_auc: 0.85107 |  0:00:59s\n",
      "epoch 148| loss: 0.01215 | val_0_auc: 0.85354 |  0:00:59s\n",
      "epoch 149| loss: 0.01355 | val_0_auc: 0.85224 |  0:01:00s\n",
      "epoch 150| loss: 0.00785 | val_0_auc: 0.85431 |  0:01:00s\n",
      "epoch 151| loss: 0.01492 | val_0_auc: 0.88099 |  0:01:00s\n",
      "epoch 152| loss: 0.00965 | val_0_auc: 0.87969 |  0:01:01s\n",
      "epoch 153| loss: 0.01034 | val_0_auc: 0.867   |  0:01:01s\n",
      "epoch 154| loss: 0.00883 | val_0_auc: 0.89653 |  0:01:02s\n",
      "epoch 155| loss: 0.00576 | val_0_auc: 0.91738 |  0:01:02s\n",
      "epoch 156| loss: 0.00866 | val_0_auc: 0.9223  |  0:01:03s\n",
      "epoch 157| loss: 0.00906 | val_0_auc: 0.9245  |  0:01:03s\n",
      "epoch 158| loss: 0.01197 | val_0_auc: 0.92515 |  0:01:04s\n",
      "epoch 159| loss: 0.01064 | val_0_auc: 0.9245  |  0:01:04s\n",
      "epoch 160| loss: 0.01398 | val_0_auc: 0.92463 |  0:01:04s\n",
      "epoch 161| loss: 0.00938 | val_0_auc: 0.92463 |  0:01:05s\n",
      "epoch 162| loss: 0.01315 | val_0_auc: 0.92489 |  0:01:05s\n",
      "epoch 163| loss: 0.00852 | val_0_auc: 0.92567 |  0:01:06s\n",
      "epoch 164| loss: 0.00727 | val_0_auc: 0.9258  |  0:01:06s\n",
      "epoch 165| loss: 0.01109 | val_0_auc: 0.92567 |  0:01:07s\n",
      "epoch 166| loss: 0.00577 | val_0_auc: 0.92567 |  0:01:07s\n",
      "epoch 167| loss: 0.0075  | val_0_auc: 0.9258  |  0:01:08s\n",
      "epoch 168| loss: 0.00796 | val_0_auc: 0.92606 |  0:01:08s\n",
      "epoch 169| loss: 0.02086 | val_0_auc: 0.92593 |  0:01:08s\n",
      "epoch 170| loss: 0.00389 | val_0_auc: 0.92618 |  0:01:09s\n",
      "epoch 171| loss: 0.00849 | val_0_auc: 0.92618 |  0:01:09s\n",
      "epoch 172| loss: 0.00415 | val_0_auc: 0.92606 |  0:01:10s\n",
      "epoch 173| loss: 0.00896 | val_0_auc: 0.92593 |  0:01:10s\n",
      "epoch 174| loss: 0.01215 | val_0_auc: 0.9258  |  0:01:11s\n",
      "epoch 175| loss: 0.0074  | val_0_auc: 0.92593 |  0:01:11s\n",
      "epoch 176| loss: 0.00912 | val_0_auc: 0.92631 |  0:01:11s\n",
      "epoch 177| loss: 0.00511 | val_0_auc: 0.9267  |  0:01:12s\n",
      "epoch 178| loss: 0.00623 | val_0_auc: 0.92606 |  0:01:12s\n",
      "epoch 179| loss: 0.00977 | val_0_auc: 0.92554 |  0:01:13s\n",
      "epoch 180| loss: 0.00321 | val_0_auc: 0.9258  |  0:01:13s\n",
      "epoch 181| loss: 0.0042  | val_0_auc: 0.92515 |  0:01:14s\n",
      "epoch 182| loss: 0.01268 | val_0_auc: 0.92567 |  0:01:14s\n",
      "epoch 183| loss: 0.01061 | val_0_auc: 0.92528 |  0:01:15s\n",
      "epoch 184| loss: 0.00264 | val_0_auc: 0.92554 |  0:01:15s\n",
      "epoch 185| loss: 0.00598 | val_0_auc: 0.92554 |  0:01:15s\n",
      "epoch 186| loss: 0.00598 | val_0_auc: 0.92567 |  0:01:16s\n",
      "epoch 187| loss: 0.01152 | val_0_auc: 0.92567 |  0:01:16s\n",
      "epoch 188| loss: 0.00402 | val_0_auc: 0.92528 |  0:01:17s\n",
      "epoch 189| loss: 0.01281 | val_0_auc: 0.92541 |  0:01:17s\n",
      "epoch 190| loss: 0.02485 | val_0_auc: 0.92606 |  0:01:18s\n",
      "epoch 191| loss: 0.02399 | val_0_auc: 0.92709 |  0:01:18s\n",
      "epoch 192| loss: 0.01363 | val_0_auc: 0.92554 |  0:01:18s\n",
      "epoch 193| loss: 0.01299 | val_0_auc: 0.92437 |  0:01:19s\n",
      "epoch 194| loss: 0.00789 | val_0_auc: 0.92385 |  0:01:19s\n",
      "epoch 195| loss: 0.00973 | val_0_auc: 0.92385 |  0:01:20s\n",
      "epoch 196| loss: 0.00892 | val_0_auc: 0.92411 |  0:01:20s\n",
      "epoch 197| loss: 0.00583 | val_0_auc: 0.92411 |  0:01:21s\n",
      "epoch 198| loss: 0.00843 | val_0_auc: 0.92424 |  0:01:21s\n",
      "epoch 199| loss: 0.01042 | val_0_auc: 0.92437 |  0:01:21s\n",
      "epoch 200| loss: 0.00316 | val_0_auc: 0.92502 |  0:01:22s\n",
      "epoch 201| loss: 0.01659 | val_0_auc: 0.92606 |  0:01:22s\n",
      "epoch 202| loss: 0.00745 | val_0_auc: 0.92644 |  0:01:23s\n",
      "epoch 203| loss: 0.00364 | val_0_auc: 0.92618 |  0:01:23s\n",
      "epoch 204| loss: 0.00931 | val_0_auc: 0.92593 |  0:01:24s\n",
      "epoch 205| loss: 0.01012 | val_0_auc: 0.9258  |  0:01:24s\n",
      "epoch 206| loss: 0.00486 | val_0_auc: 0.92631 |  0:01:24s\n",
      "epoch 207| loss: 0.00874 | val_0_auc: 0.92631 |  0:01:25s\n",
      "epoch 208| loss: 0.00491 | val_0_auc: 0.92593 |  0:01:25s\n",
      "epoch 209| loss: 0.00682 | val_0_auc: 0.92528 |  0:01:26s\n",
      "epoch 210| loss: 0.00593 | val_0_auc: 0.92489 |  0:01:26s\n",
      "epoch 211| loss: 0.00163 | val_0_auc: 0.92476 |  0:01:27s\n",
      "epoch 212| loss: 0.00271 | val_0_auc: 0.92502 |  0:01:27s\n",
      "epoch 213| loss: 0.00448 | val_0_auc: 0.92554 |  0:01:28s\n",
      "epoch 214| loss: 0.00317 | val_0_auc: 0.92618 |  0:01:28s\n",
      "epoch 215| loss: 0.00392 | val_0_auc: 0.92644 |  0:01:28s\n",
      "epoch 216| loss: 0.00623 | val_0_auc: 0.92696 |  0:01:29s\n",
      "epoch 217| loss: 0.01041 | val_0_auc: 0.92657 |  0:01:29s\n",
      "epoch 218| loss: 0.00785 | val_0_auc: 0.92644 |  0:01:30s\n",
      "epoch 219| loss: 0.00444 | val_0_auc: 0.92593 |  0:01:30s\n",
      "epoch 220| loss: 0.00761 | val_0_auc: 0.92631 |  0:01:30s\n",
      "epoch 221| loss: 0.00772 | val_0_auc: 0.9258  |  0:01:31s\n",
      "epoch 222| loss: 0.00452 | val_0_auc: 0.92618 |  0:01:31s\n",
      "epoch 223| loss: 0.00538 | val_0_auc: 0.92709 |  0:01:31s\n",
      "epoch 224| loss: 0.00362 | val_0_auc: 0.92683 |  0:01:32s\n",
      "epoch 225| loss: 0.01287 | val_0_auc: 0.9267  |  0:01:32s\n",
      "epoch 226| loss: 0.00551 | val_0_auc: 0.92657 |  0:01:32s\n",
      "epoch 227| loss: 0.0056  | val_0_auc: 0.9267  |  0:01:33s\n",
      "epoch 228| loss: 0.00651 | val_0_auc: 0.92735 |  0:01:33s\n",
      "epoch 229| loss: 0.00575 | val_0_auc: 0.92865 |  0:01:33s\n",
      "epoch 230| loss: 0.00273 | val_0_auc: 0.92877 |  0:01:34s\n",
      "epoch 231| loss: 0.005   | val_0_auc: 0.9289  |  0:01:34s\n",
      "epoch 232| loss: 0.00215 | val_0_auc: 0.92877 |  0:01:34s\n",
      "epoch 233| loss: 0.00573 | val_0_auc: 0.92877 |  0:01:35s\n",
      "epoch 234| loss: 0.00471 | val_0_auc: 0.92852 |  0:01:35s\n",
      "\n",
      "Early stopping occurred at epoch 234 with best_epoch = 134 and best_val_0_auc = 0.99922\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "clf_tabnet = TabNetClassifier()\n",
    "clf_tabnet.fit(\n",
    "  X_train, y_train,\n",
    "  eval_set=[(X_test, y_test)],\n",
    "  eval_metric=['auc'],\n",
    "    max_epochs = 300,\n",
    "    batch_size=512,\n",
    "    patience=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b6f5776-44da-4312-ab9d-5d5166a46f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9935483870967742\n",
      "AUC Score: 0.9598549598549598\n",
      "F1 Score: 0.9966329966329966\n",
      "Specificity: 0.9230769230769231\n",
      "Sensitivity: 0.9966329966329966\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        13\n",
      "           1       1.00      1.00      1.00       297\n",
      "\n",
      "    accuracy                           0.99       310\n",
      "   macro avg       0.96      0.96      0.96       310\n",
      "weighted avg       0.99      0.99      0.99       310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_tabnet.predict(X_test)\n",
    "evaluate_classifier(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad226167-58ca-44ed-a78a-a5d6804a4269",
   "metadata": {},
   "source": [
    "## TabFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e085faa8-4991-41bd-b50b-b9de2e0d098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tabpfn import TabPFNClassifier\n",
    "\n",
    "# classifier = TabPFNClassifier(device='cpu', N_ensemble_configurations=32)\n",
    "\n",
    "# classifier.fit(X_train, y_train)\n",
    "# y_pred, p_eval = classifier.predict(X_test, return_winning_probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9987706-ada8-489c-b694-a97a407eac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = classifier.predict(X_test)\n",
    "# evaluate_classifier(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d95b08-3b87-470e-9344-8cdd31b088f8",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82474817-9e4d-4503-b700-7f9dd70cadfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 8s 189ms/step - loss: 0.6597 - accuracy: 0.7540 - val_loss: 0.6232 - val_accuracy: 0.8387\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.5950 - accuracy: 0.8762 - val_loss: 0.5728 - val_accuracy: 0.8387\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5402 - accuracy: 0.8935 - val_loss: 0.5212 - val_accuracy: 0.8484\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4913 - accuracy: 0.8935 - val_loss: 0.4794 - val_accuracy: 0.8484\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.4438 - accuracy: 0.9024 - val_loss: 0.4365 - val_accuracy: 0.8645\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3998 - accuracy: 0.9112 - val_loss: 0.3978 - val_accuracy: 0.8774\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3596 - accuracy: 0.9134 - val_loss: 0.3630 - val_accuracy: 0.8871\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3218 - accuracy: 0.9210 - val_loss: 0.3354 - val_accuracy: 0.8871\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2916 - accuracy: 0.9256 - val_loss: 0.3111 - val_accuracy: 0.8935\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2650 - accuracy: 0.9294 - val_loss: 0.2875 - val_accuracy: 0.9032\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2415 - accuracy: 0.9336 - val_loss: 0.2644 - val_accuracy: 0.9194\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2213 - accuracy: 0.9358 - val_loss: 0.2448 - val_accuracy: 0.9226\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2025 - accuracy: 0.9421 - val_loss: 0.2250 - val_accuracy: 0.9258\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1881 - accuracy: 0.9446 - val_loss: 0.2089 - val_accuracy: 0.9290\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1739 - accuracy: 0.9480 - val_loss: 0.1954 - val_accuracy: 0.9290\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1625 - accuracy: 0.9522 - val_loss: 0.1848 - val_accuracy: 0.9323\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1516 - accuracy: 0.9522 - val_loss: 0.1772 - val_accuracy: 0.9323\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1426 - accuracy: 0.9531 - val_loss: 0.1670 - val_accuracy: 0.9323\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1328 - accuracy: 0.9544 - val_loss: 0.1569 - val_accuracy: 0.9355\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1242 - accuracy: 0.9552 - val_loss: 0.1483 - val_accuracy: 0.9355\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.1177 - accuracy: 0.9569 - val_loss: 0.1434 - val_accuracy: 0.9387\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1102 - accuracy: 0.9582 - val_loss: 0.1395 - val_accuracy: 0.9484\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1047 - accuracy: 0.9611 - val_loss: 0.1366 - val_accuracy: 0.9484\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1003 - accuracy: 0.9641 - val_loss: 0.1313 - val_accuracy: 0.9484\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0938 - accuracy: 0.9675 - val_loss: 0.1244 - val_accuracy: 0.9452\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0896 - accuracy: 0.9708 - val_loss: 0.1213 - val_accuracy: 0.9484\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0855 - accuracy: 0.9708 - val_loss: 0.1192 - val_accuracy: 0.9484\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0805 - accuracy: 0.9763 - val_loss: 0.1183 - val_accuracy: 0.9516\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0775 - accuracy: 0.9797 - val_loss: 0.1149 - val_accuracy: 0.9548\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0735 - accuracy: 0.9818 - val_loss: 0.1121 - val_accuracy: 0.9548\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0717 - accuracy: 0.9801 - val_loss: 0.1102 - val_accuracy: 0.9516\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0669 - accuracy: 0.9810 - val_loss: 0.1092 - val_accuracy: 0.9548\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0643 - accuracy: 0.9839 - val_loss: 0.1065 - val_accuracy: 0.9548\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0621 - accuracy: 0.9818 - val_loss: 0.1043 - val_accuracy: 0.9548\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0606 - accuracy: 0.9839 - val_loss: 0.1030 - val_accuracy: 0.9548\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0575 - accuracy: 0.9848 - val_loss: 0.1016 - val_accuracy: 0.9613\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0552 - accuracy: 0.9861 - val_loss: 0.1004 - val_accuracy: 0.9613\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0527 - accuracy: 0.9861 - val_loss: 0.0998 - val_accuracy: 0.9581\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0503 - accuracy: 0.9865 - val_loss: 0.0997 - val_accuracy: 0.9581\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0506 - accuracy: 0.9869 - val_loss: 0.1000 - val_accuracy: 0.9613\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0467 - accuracy: 0.9873 - val_loss: 0.0993 - val_accuracy: 0.9613\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0469 - accuracy: 0.9877 - val_loss: 0.0986 - val_accuracy: 0.9581\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0443 - accuracy: 0.9890 - val_loss: 0.0972 - val_accuracy: 0.9613\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0431 - accuracy: 0.9877 - val_loss: 0.0962 - val_accuracy: 0.9645\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0409 - accuracy: 0.9899 - val_loss: 0.0962 - val_accuracy: 0.9581\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0404 - accuracy: 0.9886 - val_loss: 0.0957 - val_accuracy: 0.9581\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0397 - accuracy: 0.9899 - val_loss: 0.0953 - val_accuracy: 0.9581\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 0.0950 - val_accuracy: 0.9613\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0361 - accuracy: 0.9899 - val_loss: 0.0951 - val_accuracy: 0.9645\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0948 - val_accuracy: 0.9613\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0348 - accuracy: 0.9920 - val_loss: 0.0937 - val_accuracy: 0.9613\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0325 - accuracy: 0.9924 - val_loss: 0.0939 - val_accuracy: 0.9613\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0324 - accuracy: 0.9945 - val_loss: 0.0940 - val_accuracy: 0.9613\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0315 - accuracy: 0.9932 - val_loss: 0.0935 - val_accuracy: 0.9613\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0316 - accuracy: 0.9920 - val_loss: 0.0947 - val_accuracy: 0.9613\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0297 - accuracy: 0.9945 - val_loss: 0.0946 - val_accuracy: 0.9613\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0295 - accuracy: 0.9945 - val_loss: 0.0949 - val_accuracy: 0.9613\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0284 - accuracy: 0.9945 - val_loss: 0.0950 - val_accuracy: 0.9613\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0278 - accuracy: 0.9954 - val_loss: 0.0950 - val_accuracy: 0.9613\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0259 - accuracy: 0.9958 - val_loss: 0.0950 - val_accuracy: 0.9645\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0253 - accuracy: 0.9958 - val_loss: 0.0953 - val_accuracy: 0.9613\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0255 - accuracy: 0.9954 - val_loss: 0.0945 - val_accuracy: 0.9613\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0248 - accuracy: 0.9966 - val_loss: 0.0943 - val_accuracy: 0.9613\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0242 - accuracy: 0.9958 - val_loss: 0.0943 - val_accuracy: 0.9613\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0239 - accuracy: 0.9949 - val_loss: 0.0943 - val_accuracy: 0.9613\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0235 - accuracy: 0.9970 - val_loss: 0.0952 - val_accuracy: 0.9613\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0234 - accuracy: 0.9954 - val_loss: 0.0953 - val_accuracy: 0.9645\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0220 - accuracy: 0.9975 - val_loss: 0.0958 - val_accuracy: 0.9645\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0217 - accuracy: 0.9966 - val_loss: 0.0955 - val_accuracy: 0.9645\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0209 - accuracy: 0.9966 - val_loss: 0.0950 - val_accuracy: 0.9645\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.0203 - accuracy: 0.9975 - val_loss: 0.0950 - val_accuracy: 0.9677\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0203 - accuracy: 0.9949 - val_loss: 0.0962 - val_accuracy: 0.9677\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0190 - accuracy: 0.9979 - val_loss: 0.0964 - val_accuracy: 0.9677\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0196 - accuracy: 0.9975 - val_loss: 0.0959 - val_accuracy: 0.9677\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0186 - accuracy: 0.9975 - val_loss: 0.0957 - val_accuracy: 0.9677\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0178 - accuracy: 0.9983 - val_loss: 0.0953 - val_accuracy: 0.9677\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0169 - accuracy: 0.9987 - val_loss: 0.0954 - val_accuracy: 0.9645\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0177 - accuracy: 0.9979 - val_loss: 0.0956 - val_accuracy: 0.9710\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0178 - accuracy: 0.9979 - val_loss: 0.0960 - val_accuracy: 0.9677\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0171 - accuracy: 0.9987 - val_loss: 0.0960 - val_accuracy: 0.9677\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0168 - accuracy: 0.9983 - val_loss: 0.0964 - val_accuracy: 0.9677\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0161 - accuracy: 0.9983 - val_loss: 0.0963 - val_accuracy: 0.9677\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0161 - accuracy: 0.9970 - val_loss: 0.0964 - val_accuracy: 0.9677\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0161 - accuracy: 0.9979 - val_loss: 0.0965 - val_accuracy: 0.9677\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0159 - accuracy: 0.9983 - val_loss: 0.0965 - val_accuracy: 0.9677\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0153 - accuracy: 0.9987 - val_loss: 0.0969 - val_accuracy: 0.9677\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0146 - accuracy: 0.9987 - val_loss: 0.0974 - val_accuracy: 0.9677\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0147 - accuracy: 0.9979 - val_loss: 0.0979 - val_accuracy: 0.9677\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0145 - accuracy: 0.9987 - val_loss: 0.0978 - val_accuracy: 0.9710\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.0986 - val_accuracy: 0.9677\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0140 - accuracy: 0.9987 - val_loss: 0.0980 - val_accuracy: 0.9710\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0139 - accuracy: 0.9987 - val_loss: 0.0986 - val_accuracy: 0.9710\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0140 - accuracy: 0.9983 - val_loss: 0.0976 - val_accuracy: 0.9742\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.0980 - val_accuracy: 0.9742\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0131 - accuracy: 0.9983 - val_loss: 0.0984 - val_accuracy: 0.9742\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0122 - accuracy: 0.9992 - val_loss: 0.0986 - val_accuracy: 0.9742\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0122 - accuracy: 0.9992 - val_loss: 0.0994 - val_accuracy: 0.9710\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0130 - accuracy: 0.9987 - val_loss: 0.0992 - val_accuracy: 0.9710\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0117 - accuracy: 0.9992 - val_loss: 0.0988 - val_accuracy: 0.9710\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0120 - accuracy: 0.9987 - val_loss: 0.0991 - val_accuracy: 0.9710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1951f8a7910>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape input data to fit the LSTM layer\n",
    "# LSTM expects input data in the shape (samples, timesteps, features)\n",
    "# Here, assuming 23 features\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Creating the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dropout(0.2))  # Optional dropout layer for regularization\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=256, validation_data=(X_test_reshaped, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd24203d-3adb-4b4b-917c-01115b977ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred >= .5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35c0da9a-3476-4907-8e9e-eb9b2cd47bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9709677419354839\n",
      "AUC Score: 0.8377363377363378\n",
      "F1 Score: 0.984822934232715\n",
      "Specificity: 0.6923076923076923\n",
      "Sensitivity: 0.9831649831649831\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.67        13\n",
      "           1       0.99      0.98      0.98       297\n",
      "\n",
      "    accuracy                           0.97       310\n",
      "   macro avg       0.81      0.84      0.83       310\n",
      "weighted avg       0.97      0.97      0.97       310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f24aa-f04e-43cf-a05d-4491957dc6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
